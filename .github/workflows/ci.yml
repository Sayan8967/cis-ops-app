name: CI/CD Pipeline

on:
  push:
    branches: [ release ]
  pull_request:
    branches: [ release ]

env:
  DOCKER_REGISTRY: ${{ secrets.DOCKER_REGISTRY }}
  BACKEND_IMAGE: cis-ops-backend
  FRONTEND_IMAGE: cis-ops-frontend

jobs:
  # Backend Build Job
  build-backend:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '18'
          cache: 'npm'
          cache-dependency-path: backend/package-lock.json
          
      - name: Install backend dependencies
        run: |
          cd backend
          npm ci
          
      - name: Build backend
        run: |
          cd backend
          npm run build --if-present

  # Frontend Build Job
  build-frontend:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '18'
          cache: 'npm'
          cache-dependency-path: frontend/package-lock.json
          
      - name: Install frontend dependencies
        run: |
          cd frontend
          npm ci
          
      - name: Build frontend
        run: |
          cd frontend
          npm run build
        env:
          REACT_APP_HF_API_KEY: ${{ secrets.REACT_APP_HF_API_KEY }}
          REACT_APP_GOOGLE_CLIENT_ID: ${{ secrets.REACT_APP_GOOGLE_CLIENT_ID }}

  # Docker Build and Push Jobs
  docker-backend:
    needs: build-backend
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v2
        
      - name: Login to Docker Registry
        run: |
          docker login -u ${{ secrets.DOCKER_USERNAME }} -p ${{ secrets.DOCKER_REGISTRY_KEY }}
      
      - name: Build and Push Backend Docker image
        uses: docker/build-push-action@v4
        with:
          context: ./backend
          push: true
          tags: ${{ env.DOCKER_REGISTRY }}/${{ env.BACKEND_IMAGE }}:${{ github.sha }}
          file: backend/Dockerfile
          cache-from: type=gha
          cache-to: type=gha,mode=max

  docker-frontend:
    needs: build-frontend
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v2
        
      - name: Login to Docker Registry
        run: |
          docker login -u ${{ secrets.DOCKER_USERNAME }} -p ${{ secrets.DOCKER_REGISTRY_KEY }}
      
      - name: Build and Push Frontend Docker image
        uses: docker/build-push-action@v4
        with:
          context: ./frontend
          push: true
          tags: ${{ env.DOCKER_REGISTRY }}/${{ env.FRONTEND_IMAGE }}:${{ github.sha }}
          file: frontend/Dockerfile
          build-args: |
            REACT_APP_HF_API_KEY=${{ secrets.REACT_APP_HF_API_KEY }}
            REACT_APP_GOOGLE_CLIENT_ID=${{ secrets.REACT_APP_GOOGLE_CLIENT_ID }}
          cache-from: type=gha
          cache-to: type=gha,mode=max

  # Security Scanning
  trivy-scan-backend:
    needs: docker-backend
    runs-on: ubuntu-latest
    steps:
      - name: Run Trivy vulnerability scanner - Backend
        uses: aquasecurity/trivy-action@master
        with:
          image-ref: ${{ env.DOCKER_REGISTRY }}/${{ env.BACKEND_IMAGE }}:${{ github.sha }}
          format: 'sarif'
          output: 'backend-trivy-results.sarif'
          
      - name: Upload Trivy scan results - Backend
        uses: github/codeql-action/upload-sarif@v3
        if: always()
        with:
          sarif_file: 'backend-trivy-results.sarif'

  trivy-scan-frontend:
    needs: docker-frontend
    runs-on: ubuntu-latest
    steps:
      - name: Run Trivy vulnerability scanner - Frontend
        uses: aquasecurity/trivy-action@master
        with:
          image-ref: ${{ env.DOCKER_REGISTRY }}/${{ env.FRONTEND_IMAGE }}:${{ github.sha }}
          format: 'sarif'
          output: 'frontend-trivy-results.sarif'
          
      - name: Upload Trivy scan results - Frontend
        uses: github/codeql-action/upload-sarif@v3
        if: always()
        with:
          sarif_file: 'frontend-trivy-results.sarif'

  # Generate Kubernetes Manifests
  k8s-manifest:
    needs: [trivy-scan-backend, trivy-scan-frontend]
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          
      - name: Configure Git
        run: |
          git config user.name "github-actions"
          git config user.email "github-actions@github.com"
          
      - name: Generate Kubernetes manifests
        run: |
          mkdir -p deployment/k8s
          
          # Create Namespace
          cat <<EOF > deployment/k8s/namespace.yml
          apiVersion: v1
          kind: Namespace
          metadata:
            name: cis-ops
            labels:
              name: cis-ops
          EOF
          
          # Create ConfigMap for environment variables
          cat <<EOF > deployment/k8s/configmap.yml
          apiVersion: v1
          kind: ConfigMap
          metadata:
            name: cis-ops-config
            namespace: cis-ops
          data:
            NODE_ENV: "production"
            PORT: "4000"
          EOF
          
          # Create Backend Deployment
          cat <<EOF > deployment/k8s/backend-deployment.yml
          apiVersion: apps/v1
          kind: Deployment
          metadata:
            name: cis-ops-backend
            namespace: cis-ops
            labels:
              app: cis-ops-backend
          spec:
            replicas: 2
            selector:
              matchLabels:
                app: cis-ops-backend
            template:
              metadata:
                labels:
                  app: cis-ops-backend
              spec:
                containers:
                - name: backend
                  image: ${{ env.DOCKER_REGISTRY }}/${{ env.BACKEND_IMAGE }}:${{ github.sha }}
                  ports:
                  - containerPort: 4000
                    name: http
                  envFrom:
                  - configMapRef:
                      name: cis-ops-config
                  resources:
                    requests:
                      memory: "256Mi"
                      cpu: "250m"
                    limits:
                      memory: "512Mi"
                      cpu: "500m"
                  livenessProbe:
                    httpGet:
                      path: /api/metrics
                      port: 4000
                    initialDelaySeconds: 30
                    periodSeconds: 10
                  readinessProbe:
                    httpGet:
                      path: /api/metrics
                      port: 4000
                    initialDelaySeconds: 5
                    periodSeconds: 5
          ---
          apiVersion: v1
          kind: Service
          metadata:
            name: cis-ops-backend-service
            namespace: cis-ops
            labels:
              app: cis-ops-backend
          spec:
            selector:
              app: cis-ops-backend
            ports:
            - name: http
              port: 4000
              targetPort: 4000
            type: ClusterIP
          EOF
          
          # Create Frontend Deployment
          cat <<EOF > deployment/k8s/frontend-deployment.yml
          apiVersion: apps/v1
          kind: Deployment
          metadata:
            name: cis-ops-frontend
            namespace: cis-ops
            labels:
              app: cis-ops-frontend
          spec:
            replicas: 2
            selector:
              matchLabels:
                app: cis-ops-frontend
            template:
              metadata:
                labels:
                  app: cis-ops-frontend
              spec:
                containers:
                - name: frontend
                  image: ${{ env.DOCKER_REGISTRY }}/${{ env.FRONTEND_IMAGE }}:${{ github.sha }}
                  ports:
                  - containerPort: 80
                    name: http
                  resources:
                    requests:
                      memory: "128Mi"
                      cpu: "100m"
                    limits:
                      memory: "256Mi"
                      cpu: "200m"
                  livenessProbe:
                    httpGet:
                      path: /
                      port: 80
                    initialDelaySeconds: 30
                    periodSeconds: 10
                  readinessProbe:
                    httpGet:
                      path: /
                      port: 80
                    initialDelaySeconds: 5
                    periodSeconds: 5
          ---
          apiVersion: v1
          kind: Service
          metadata:
            name: cis-ops-frontend-service
            namespace: cis-ops
            labels:
              app: cis-ops-frontend
          spec:
            selector:
              app: cis-ops-frontend
            ports:
            - name: http
              port: 80
              targetPort: 80
            type: ClusterIP
          EOF
          
          # Create Ingress with webhook bypass and flexible configuration
          cat <<EOF > deployment/k8s/ingress.yml
          apiVersion: networking.k8s.io/v1
          kind: Ingress
          metadata:
            name: cis-ops-ingress
            namespace: cis-ops
            annotations:
              # Multiple ingress class annotations for compatibility
              kubernetes.io/ingress.class: "nginx"
              nginx.ingress.kubernetes.io/ingress.class: "nginx"
              
              # Webhook bypass to prevent admission webhook issues
              nginx.ingress.kubernetes.io/disable-admission-webhook: "true"
              
              # SSL and routing configuration
              nginx.ingress.kubernetes.io/ssl-redirect: "false"
              nginx.ingress.kubernetes.io/force-ssl-redirect: "false"
              
              # Backend protocol and routing
              nginx.ingress.kubernetes.io/backend-protocol: "HTTP"
              nginx.ingress.kubernetes.io/proxy-body-size: "50m"
              
              # CORS configuration for API calls
              nginx.ingress.kubernetes.io/enable-cors: "true"
              nginx.ingress.kubernetes.io/cors-allow-origin: "*"
              nginx.ingress.kubernetes.io/cors-allow-methods: "GET, POST, PUT, DELETE, OPTIONS"
              nginx.ingress.kubernetes.io/cors-allow-headers: "DNT,X-CustomHeader,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Authorization"
              
              # WebSocket support
              nginx.ingress.kubernetes.io/proxy-read-timeout: "3600"
              nginx.ingress.kubernetes.io/proxy-send-timeout: "3600"
              nginx.ingress.kubernetes.io/websocket-services: "cis-ops-backend-service"
          spec:
            # Use ingressClassName as backup
            ingressClassName: nginx
            rules:
            # Default rule without host for flexibility
            - http:
                paths:
                - path: /api
                  pathType: Prefix
                  backend:
                    service:
                      name: cis-ops-backend-service
                      port:
                        number: 4000
                - path: /socket.io
                  pathType: Prefix
                  backend:
                    service:
                      name: cis-ops-backend-service
                      port:
                        number: 4000
                - path: /
                  pathType: Prefix
                  backend:
                    service:
                      name: cis-ops-frontend-service
                      port:
                        number: 80
            # Optional: Add specific host rule if you have a domain
            # Uncomment and modify the section below if you have a specific domain
            # - host: your-domain.com
            #   http:
            #     paths:
            #     - path: /api
            #       pathType: Prefix
            #       backend:
            #         service:
            #           name: cis-ops-backend-service
            #           port:
            #             number: 4000
            #     - path: /socket.io
            #       pathType: Prefix
            #       backend:
            #         service:
            #           name: cis-ops-backend-service
            #           port:
            #             number: 4000
            #     - path: /
            #       pathType: Prefix
            #       backend:
            #         service:
            #           name: cis-ops-frontend-service
            #           port:
            #             number: 80
          EOF
          
          # Create NGINX Ingress Controller installation manifest (if needed)
          cat <<EOF > deployment/k8s/ingress-controller-install.yml
          # This file can be used to install NGINX Ingress Controller if not present
          # Run: kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.8.2/deploy/static/provider/cloud/deploy.yaml
          # Or for bare metal: kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.8.2/deploy/static/provider/baremetal/deploy.yaml
          
          # Alternatively, create a simple ingress controller service patch for NodePort access
          apiVersion: v1
          kind: Service
          metadata:
            name: ingress-nginx-controller-nodeport
            namespace: ingress-nginx
            labels:
              app.kubernetes.io/name: ingress-nginx
              app.kubernetes.io/part-of: ingress-nginx
          spec:
            type: NodePort
            ports:
            - name: http
              port: 80
              protocol: TCP
              targetPort: http
              nodePort: 30080
            - name: https
              port: 443
              protocol: TCP
              targetPort: https
              nodePort: 30443
            selector:
              app.kubernetes.io/name: ingress-nginx
              app.kubernetes.io/instance: ingress-nginx
              app.kubernetes.io/component: controller
          EOF

      - name: Generate Grafana Cloud Monitoring Values
        run: |
          mkdir -p deployment/helm
          
          # Create Grafana Cloud K8s Monitoring values file
          cat <<EOF > deployment/helm/grafana-cloud-values.yml
          # Grafana Cloud K8s Monitoring Values
          cluster:
            name: cis-ops-cluster
          destinations:
            - name: grafana-cloud-metrics
              type: prometheus
              url: ${{ secrets.GRAFANA_PROMETHEUS_URL }}
              auth:
                type: basic
                username: ${{ secrets.GRAFANA_PROMETHEUS_USERNAME }}
                password: ${{ secrets.GRAFANA_CLOUD_TOKEN }}
            - name: grafana-cloud-logs
              type: loki
              url: ${{ secrets.GRAFANA_LOKI_URL }}
              auth:
                type: basic
                username: ${{ secrets.GRAFANA_LOKI_USERNAME }}
                password: ${{ secrets.GRAFANA_CLOUD_TOKEN }}
            - name: grafana-cloud-otlp-endpoint
              type: otlp
              url: ${{ secrets.GRAFANA_OTLP_URL }}
              protocol: http
              auth:
                type: basic
                username: ${{ secrets.GRAFANA_OTLP_USERNAME }}
                password: ${{ secrets.GRAFANA_CLOUD_TOKEN }}
              metrics:
                enabled: true
              logs:
                enabled: true
              traces:
                enabled: true
            - name: grafana-cloud-profiles
              type: pyroscope
              url: ${{ secrets.GRAFANA_PROFILES_URL }}
              auth:
                type: basic
                username: ${{ secrets.GRAFANA_PROFILES_USERNAME }}
                password: ${{ secrets.GRAFANA_CLOUD_TOKEN }}
          clusterMetrics:
            enabled: true
            opencost:
              enabled: true
              metricsSource: grafana-cloud-metrics
              opencost:
                exporter:
                  defaultClusterId: cis-ops-cluster
                prometheus:
                  existingSecretName: grafana-cloud-metrics-grafana-k8s-monitoring
                  external:
                    url: ${{ secrets.GRAFANA_PROMETHEUS_URL }}
            kepler:
              enabled: true
          annotationAutodiscovery:
            enabled: true
          prometheusOperatorObjects:
            enabled: true
          clusterEvents:
            enabled: true
          nodeLogs:
            enabled: true
          podLogs:
            enabled: true
          applicationObservability:
            enabled: true
            receivers:
              otlp:
                grpc:
                  enabled: true
                  port: 4317
                http:
                  enabled: true
                  port: 4318
              zipkin:
                enabled: true
                port: 9411
            connectors:
              grafanaCloudMetrics:
                enabled: true
          autoInstrumentation:
            enabled: true
          profiling:
            enabled: true
          alloy-metrics:
            enabled: true
            alloy:
              extraEnv:
                - name: GCLOUD_RW_API_KEY
                  valueFrom:
                    secretKeyRef:
                      name: alloy-metrics-remote-cfg-grafana-k8s-monitoring
                      key: password
                - name: CLUSTER_NAME
                  value: cis-ops-cluster
                - name: NAMESPACE
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.namespace
                - name: POD_NAME
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.name
                - name: GCLOUD_FM_COLLECTOR_ID
                  value: grafana-k8s-monitoring-$(CLUSTER_NAME)-$(NAMESPACE)-$(POD_NAME)
            remoteConfig:
              enabled: true
              url: ${{ secrets.GRAFANA_FLEET_MANAGEMENT_URL }}
              auth:
                type: basic
                username: ${{ secrets.GRAFANA_FLEET_USERNAME }}
                password: ${{ secrets.GRAFANA_CLOUD_TOKEN }}
          alloy-singleton:
            enabled: true
            remoteConfig:
              enabled: true
              url: ${{ secrets.GRAFANA_FLEET_MANAGEMENT_URL }}
              auth:
                type: basic
                username: ${{ secrets.GRAFANA_FLEET_USERNAME }}
                password: ${{ secrets.GRAFANA_CLOUD_TOKEN }}
          alloy-logs:
            enabled: true
            remoteConfig:
              enabled: true
              url: ${{ secrets.GRAFANA_FLEET_MANAGEMENT_URL }}
              auth:
                type: basic
                username: ${{ secrets.GRAFANA_FLEET_USERNAME }}
                password: ${{ secrets.GRAFANA_CLOUD_TOKEN }}
          alloy-receiver:
            enabled: true
            alloy:
              extraPorts:
                - name: otlp-grpc
                  port: 4317
                  targetPort: 4317
                  protocol: TCP
                - name: otlp-http
                  port: 4318
                  targetPort: 4318
                  protocol: TCP
                - name: zipkin
                  port: 9411
                  targetPort: 9411
                  protocol: TCP
            remoteConfig:
              enabled: true
              url: ${{ secrets.GRAFANA_FLEET_MANAGEMENT_URL }}
              auth:
                type: basic
                username: ${{ secrets.GRAFANA_FLEET_USERNAME }}
                password: ${{ secrets.GRAFANA_CLOUD_TOKEN }}
          alloy-profiles:
            enabled: true
            remoteConfig:
              enabled: true
              url: ${{ secrets.GRAFANA_FLEET_MANAGEMENT_URL }}
              auth:
                type: basic
                username: ${{ secrets.GRAFANA_FLEET_USERNAME }}
                password: ${{ secrets.GRAFANA_CLOUD_TOKEN }}
          EOF
          
          # Create deployment script with ingress controller check
          cat <<EOF > deployment/deploy.sh
          #!/bin/bash
          set -e
          
          echo "Deploying CIS Operations Dashboard..."
          
          # Check if NGINX Ingress Controller is installed
          if ! kubectl get namespace ingress-nginx >/dev/null 2>&1; then
            echo "NGINX Ingress Controller not found. Installing..."
            
            # Detect if running on cloud provider or bare metal
            if kubectl get nodes -o jsonpath='{.items[*].spec.providerID}' | grep -q "^$"; then
              echo "Installing NGINX Ingress Controller for bare metal..."
              kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.8.2/deploy/static/provider/baremetal/deploy.yaml
            else
              echo "Installing NGINX Ingress Controller for cloud provider..."
              kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.8.2/deploy/static/provider/cloud/deploy.yaml
            fi
            
            echo "Waiting for NGINX Ingress Controller to be ready..."
            kubectl wait --namespace ingress-nginx \
              --for=condition=ready pod \
              --selector=app.kubernetes.io/component=controller \
              --timeout=300s
          else
            echo "NGINX Ingress Controller already installed."
          fi
          
          # Apply Kubernetes manifests
          echo "Applying Kubernetes manifests..."
          kubectl apply -f k8s/namespace.yml
          kubectl apply -f k8s/configmap.yml
          kubectl apply -f k8s/backend-deployment.yml
          kubectl apply -f k8s/frontend-deployment.yml
          
          # Apply ingress with retry logic
          echo "Applying ingress configuration..."
          for i in {1..3}; do
            if kubectl apply -f k8s/ingress.yml; then
              echo "Ingress applied successfully"
              break
            else
              echo "Ingress application failed, attempt \$i/3"
              if [ \$i -eq 3 ]; then
                echo "Failed to apply ingress after 3 attempts"
                exit 1
              fi
              sleep 10
            fi
          done
          
          # Apply NodePort service for ingress controller if needed
          if kubectl get svc -n ingress-nginx ingress-nginx-controller -o jsonpath='{.spec.type}' | grep -q "ClusterIP"; then
            echo "Creating NodePort service for ingress access..."
            kubectl apply -f k8s/ingress-controller-install.yml
          fi
          
          # Install/Upgrade Grafana Cloud K8s Monitoring using Helm
          echo "Installing Grafana Cloud monitoring..."
          helm repo add grafana https://grafana.github.io/helm-charts
          helm repo update
          
          helm upgrade --install --atomic --timeout 300s grafana-k8s-monitoring grafana/k8s-monitoring \\
            --namespace "monitoring" \\
            --create-namespace \\
            --values helm/grafana-cloud-values.yml
          
          echo "Deployment completed successfully!"
          echo ""
          echo "=== Access Information ==="
          
          # Get ingress controller service info
          INGRESS_SERVICE=\$(kubectl get svc -n ingress-nginx -o jsonpath='{.items[0].metadata.name}')
          SERVICE_TYPE=\$(kubectl get svc -n ingress-nginx \$INGRESS_SERVICE -o jsonpath='{.spec.type}')
          
          if [ "\$SERVICE_TYPE" = "LoadBalancer" ]; then
            EXTERNAL_IP=\$(kubectl get svc -n ingress-nginx \$INGRESS_SERVICE -o jsonpath='{.status.loadBalancer.ingress[0].ip}')
            if [ -z "\$EXTERNAL_IP" ]; then
              EXTERNAL_IP=\$(kubectl get svc -n ingress-nginx \$INGRESS_SERVICE -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')
            fi
            echo "Access your application at: http://\$EXTERNAL_IP"
          elif [ "\$SERVICE_TYPE" = "NodePort" ]; then
            NODE_IP=\$(kubectl get nodes -o jsonpath='{.items[0].status.addresses[?(@.type=="ExternalIP")].address}')
            if [ -z "\$NODE_IP" ]; then
              NODE_IP=\$(kubectl get nodes -o jsonpath='{.items[0].status.addresses[?(@.type=="InternalIP")].address}')
            fi
            NODE_PORT=\$(kubectl get svc -n ingress-nginx \$INGRESS_SERVICE -o jsonpath='{.spec.ports[?(@.name=="http")].nodePort}')
            echo "Access your application at: http://\$NODE_IP:\$NODE_PORT"
          else
            echo "Use kubectl port-forward to access your application:"
            echo "kubectl port-forward -n ingress-nginx svc/\$INGRESS_SERVICE 8080:80"
            echo "Then visit: http://localhost:8080"
          fi
          
          echo "Access Grafana Cloud dashboard at your Grafana Cloud instance"
          echo "Monitoring data will be sent to Grafana Cloud automatically"
          
          echo ""
          echo "=== Useful Commands ==="
          echo "Check application status: kubectl get all -n cis-ops"
          echo "Check ingress status: kubectl get ingress -n cis-ops"
          echo "View application logs: kubectl logs -n cis-ops deployment/cis-ops-frontend"
          echo "View backend logs: kubectl logs -n cis-ops deployment/cis-ops-backend"
          EOF
          
          chmod +x deployment/deploy.sh
          
      - name: Commit and push manifests to repo
        run: |
          git pull origin release || echo "No changes to pull"
          git add deployment/
          git commit -m "Update k8s manifests with improved ingress config for ${{ github.sha }}" || echo "No changes to commit"
          git push origin release
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          
      - name: Create deployment summary
        run: |
          echo "## Deployment Summary" >> $GITHUB_STEP_SUMMARY
          echo "- **Backend Image**: \`${{ env.DOCKER_REGISTRY }}/${{ env.BACKEND_IMAGE }}:${{ github.sha }}\`" >> $GITHUB_STEP_SUMMARY
          echo "- **Frontend Image**: \`${{ env.DOCKER_REGISTRY }}/${{ env.FRONTEND_IMAGE }}:${{ github.sha }}\`" >> $GITHUB_STEP_SUMMARY
          echo "- **Namespace**: \`cis-ops\`" >> $GITHUB_STEP_SUMMARY
          echo "- **Ingress**: Configured with webhook bypass and CORS support" >> $GITHUB_STEP_SUMMARY
          echo "- **Monitoring**: Grafana Cloud integration in \`monitoring\` namespace" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Ingress Configuration:" >> $GITHUB_STEP_SUMMARY
          echo "- ✅ Webhook bypass enabled" >> $GITHUB_STEP_SUMMARY
          echo "- ✅ CORS configured for API calls" >> $GITHUB_STEP_SUMMARY
          echo "- ✅ WebSocket support enabled" >> $GITHUB_STEP_SUMMARY
          echo "- ✅ Flexible host configuration (works with any domain/IP)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Next Steps:" >> $GITHUB_STEP_SUMMARY
          echo "1. ArgoCD will automatically sync the updated manifests" >> $GITHUB_STEP_SUMMARY
          echo "2. Access your application through the ingress controller" >> $GITHUB_STEP_SUMMARY
          echo "3. Check ingress status: \`kubectl get ingress -n cis-ops\`" >> $GITHUB_STEP_SUMMARY
          echo "4. Access Grafana Cloud dashboard at your Grafana Cloud instance" >> $GITHUB_STEP_SUMMARY